Notes from May 27-28 tests with 100_000 particles

Here’s the printout from today’s GFP test.

elapsed time: 8536.369724353 seconds
This test was run at time 2015-05-27T10:37:13 with observations at intervals of 300.0 from time zero to 7200.0 with a noise sd of 10.0.  There were 100000 particles,  with a log-uniform prior between 1 and 1e-4 and  true rates of [0.1,0.0002,1.0,0.0002,1.0,0.0002,0.01,0.1,0.02,0.1,0.01,0.1,1.0,0.0002,0.01,0.1,0.01,0.1]. 
 The observed molecule was GFP at index 13. 
 It took 8536.369724353 seconds.
By round, the acceptance rate was [0.05341317365269461,7.385229540918164e-5,0.7243233532934131,0.973874251497006,0.9989580838323353,0.9999760479041916,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]

So, the test took ca 2.5 hours. The posterior was concentrated around a single point, way off in the wrong place.  7.385229540918164e-5 times 501000 is exactly 37, so all but 37 proposals got rejected in stage 2, and before that all but 5% got rejected in stage 1. After that, every proposal started getting accepted, causing things to fan out into the cloud in the posterior. Is this just how the method works? Too big of a gap between P(\theta) and P(\theta|D_{t_1})?

This problem has been occurring persistently: very high rejections in early rounds. I wonder if everything is correct: haven’t tested correctness well enough since the big encapsulation event. So, I’m re-doing a correctness test that I did early on. It looks good: the sampler recovers the hidden state pretty well with only 10,000 particles.